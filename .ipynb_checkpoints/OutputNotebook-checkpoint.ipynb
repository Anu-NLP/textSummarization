{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94dbe7b8-08c1-4ec2-9d61-2b82c69d04bd",
   "metadata": {},
   "source": [
    "## Bart Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb12071d-e75c-44f2-966a-8053ef98ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: VNware isn't taking the user's MS password. If user enters the password then after about 30 seconds later, then its MFA. If you have not remove MFA/All the Phone and the Authenticator Methods and then re-add them, they may not work.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the pre-trained BART model and tokenizer\n",
    "model_name   = 'facebook/bart-large-cnn'\n",
    "model        = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer    = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def summarize_chat(chat_text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + chat_text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example chat conversation\n",
    "chat_conversation = \"\"\"\n",
    "Hello\n",
    "Dora\n",
    "1:14:37 PM\n",
    "We will be with you soon.\n",
    "System\n",
    "1:14:39 PM\n",
    "I have a user that can't get into SAW.\n",
    "Dora\n",
    "1:14:53 PM\n",
    "hello\n",
    "Pat\n",
    "1:15:15 PM\n",
    "It is saying his MS password is wrong.\n",
    "Dora\n",
    "1:15:28 PM\n",
    "We have tested MS password and it is correct.\n",
    "Dora\n",
    "1:15:42 PM\n",
    "User received a new phone- we have added it and registered it.\n",
    "Dora\n",
    "1:16:40 PM\n",
    "probably MFA issue..not sync\n",
    "Pat\n",
    "1:16:45 PM\n",
    "User can received codes\n",
    "Dora\n",
    "1:17:12 PM\n",
    "and user accepted the code and if they do, they accepted within the 30 seconds \n",
    "Pat\n",
    "1:18:08 PM\n",
    "do you have ticket number?\n",
    "Pat\n",
    "1:18:23 PM\n",
    "user launches the My workbench and it aasked for MS password, can't get pass that screen.\n",
    "Dora\n",
    "1:18:55 PM\n",
    "INC35033253\n",
    "Dora\n",
    "1:19:40 PM\n",
    "If user enter the MS password and Immediately gets the error, then possible password issue. BUT if user enters the password then after about 30 seconds later, then its MFA \n",
    "Pat\n",
    "1:21:03 PM\n",
    "VNware isn't taking the user's MS password\n",
    "Dora\n",
    "1:22:53 PM\n",
    "MS password has been verify correctly.\n",
    "Dora\n",
    "1:23:13 PM\n",
    "I see user has the SAW access....you can send the ticket to me if you ran out of options\n",
    "Pat\n",
    "1:25:09 PM\n",
    "Give me your name,\n",
    "Dora\n",
    "1:26:38 PM\n",
    "We just tested the MFA again and the user can get code, so it's working.\n",
    "Dora\n",
    "1:28:11 PM\n",
    "Did you say you already removed and readd the MFA?\n",
    "Pat\n",
    "1:29:40 PM\n",
    "If user can't get password the first sign on...it is MFA. If you have not remove MFA/All the Phone and the Authenticator Methods and then re-add\n",
    "Pat\n",
    "1:31:13 PM\n",
    "and see if that fix but if not please send the ticket to me\n",
    "Pat\n",
    "1:31:41 PM\n",
    "ok, sounds good.\n",
    "Dora\n",
    "1:32:38 PM\n",
    "Did you open a coach task for this?\n",
    "Dora\n",
    "1:33:40 PM\n",
    "yes\n",
    "Pat\n",
    "1:33:52 PM\n",
    "I'll get your name from there. Thanks! .\n",
    "Dora\n",
    "1:34:09 PM\n",
    "Great..thanks. Let user I know I will connect with him within 30 mins\n",
    "Pat\n",
    "1:35:16 PM\n",
    "am Bomgar into the user if you want to join?\n",
    "Dora\n",
    "1:36:35 PM\n",
    "sure\n",
    "Pat\n",
    "1:36:55 PM\n",
    "I am logged on \n",
    "Pat\n",
    "1:37:22 PM\n",
    "hi Darrell...are we good to leave the chat?\n",
    "Pat\n",
    "1:55:41 PM\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the chat conversation\n",
    "summary = summarize_chat(chat_conversation)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571e91f-651e-4a5e-a836-cb08c7fa5111",
   "metadata": {},
   "source": [
    "## T5-small Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc07849a-e8c2-4d20-abb7-33525273bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: system 1:14:41 PM INC34999990 Mac 1:14:43 PM You are currently 1 in queue. system 1:15:41 PM INC349223344 Mac 1:16:07 PM Good morning Dev 1:16:31 PM see screen shot. it blips on and off where you cant read it (its the yellow error)\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the pre-trained T5 model and tokenizer\n",
    "model_name = 't5-small'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def summarize_chat(chat_text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + chat_text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example chat conversation\n",
    "chat_conversation = \"\"\"\n",
    "1:14:11 PM\n",
    "You are currently 1 in queue.\n",
    "System\n",
    "1:14:41 PM\n",
    "INC34999990\n",
    "Mac\n",
    "1:14:43 PM\n",
    "You are currently 1 in queue.\n",
    "System\n",
    "1:15:41 PM\n",
    "INC349223344\n",
    "Mac\n",
    "1:16:07 PM\n",
    "Good morning\n",
    "Dev\n",
    "1:16:31 PM\n",
    "kindly give me a minute to review the ticket\n",
    "Dev\n",
    "1:16:40 PM\n",
    "Metered error in Outlook?\n",
    "Dev\n",
    "1:19:15 PM\n",
    "see screen shot. it blips on and off where you cant read it (its the yellow error) and i was able to snap a shot right when it appeared before disappearing again over and over\n",
    "Mac\n",
    "1:20:05 PM\n",
    "can you add me into bomgar?\n",
    "Dev\n",
    "1:20:36 PM\n",
    "yes\n",
    "Mac\n",
    "1:20:41 PM\n",
    "ty\n",
    "Dev\n",
    "1:20:49 PM\n",
    "she should be good to go now, we turned off the metered connection setting and I sent her a successful test email\n",
    "Dev\n",
    "1:25:46 PM\n",
    "thanks a lot Devlin. you are awesome\n",
    "Mac\n",
    "1:26:13 PM\n",
    "what would i use for a KB?\n",
    "Mac\n",
    "1:26:45 PM\n",
    "My pleasure you are very welcome!! KB1045193 and Microsoft Outlook - Unable to Connect or Connection is Unavailable and KB104939 \n",
    "Dev\n",
    "1:26:50 PM\n",
    "thanks\n",
    "Mac\n",
    "1:27:00 PM\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the chat conversation\n",
    "summary = summarize_chat(chat_conversation)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1ed32-27be-49af-8aac-864f36b21bfc",
   "metadata": {},
   "source": [
    "## Pegasus Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45403a8b-00ca-4a9b-b9d3-492c70e58b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Mac 1:15:41 PM INC34955425 Mac 1:15:43 PM You are currently 1 in queue. System 1:15:41 PM INC34955425 Mac 1:16:07 PM Good morning Dev 1:16:31 PM kindly give me a minute to review the ticket Dev 1:16:40 PM Metered error in Outlook?\n"
     ]
    }
   ],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "# Load the pre-trained Pegasus model and tokenizer\n",
    "model_name = 'google/pegasus-xsum'\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def summarize_chat(chat_text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer.encode(chat_text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example chat conversation\n",
    "chat_conversation = \"\"\"\n",
    "1:14:41 PM\n",
    "INC34955425\n",
    "Mac\n",
    "1:14:43 PM\n",
    "You are currently 1 in queue.\n",
    "System\n",
    "1:15:41 PM\n",
    "INC34955425\n",
    "Mac\n",
    "1:16:07 PM\n",
    "Good morning\n",
    "Dev\n",
    "1:16:31 PM\n",
    "kindly give me a minute to review the ticket\n",
    "Dev\n",
    "1:16:40 PM\n",
    "Metered error in Outlook?\n",
    "Dev\n",
    "1:19:15 PM\n",
    "see screen shot. it blips on and off where you cant read it (its the yellow error) and i was able to snap a shot right when it appeared before disappearing again over and over\n",
    "Mac\n",
    "1:20:05 PM\n",
    "can you add me into bomgar?\n",
    "Dev\n",
    "1:20:36 PM\n",
    "yes\n",
    "Mac\n",
    "1:20:41 PM\n",
    "ty\n",
    "Dev\n",
    "1:20:49 PM\n",
    "she should be good to go now, we turned off the metered connection setting and I sent her a successful test email\n",
    "Dev\n",
    "1:25:46 PM\n",
    "thanks a lot Devlin. you are awesome\n",
    "Mac\n",
    "1:26:13 PM\n",
    "what would i use for a KB?\n",
    "Mac\n",
    "1:26:45 PM\n",
    "My pleasure you are very welcome!! KBB0045163 and Microsoft Outlook - Unable to Connect or Connection is UnavailableKB0104935\n",
    "Dev\n",
    "1:26:50 PM\n",
    "thanks\n",
    "Mac\n",
    "1:27:00 PM\n",
    "\"\"\"\n",
    "\n",
    "# Summarize the chat conversation\n",
    "summary = summarize_chat(chat_conversation)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7841930-f36d-4a21-aef7-2dd8f9b99dca",
   "metadata": {},
   "source": [
    "## Gpt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1f962a-fe8b-40d1-b06d-f76a09306115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=150) and `max_length`(=500) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary \n",
      "We will be with you soon.\n",
      "System\n",
      "1:14:11 PM\n",
      "You are currently 1 in queue.\n",
      "System\n",
      "1:14:41 PM\n",
      "INC34955425\n",
      "MICHAEL BORCHARDT\n",
      "1:14:43 PM\n",
      "You are currently 1 in queue.\n",
      "System\n",
      "1:15:41 PM\n",
      "INC34955425\n",
      "MICHAEL BORCHARDT\n",
      "1:16:07 PM\n",
      "Good morning\n",
      "Eddens,Devlin (COACH)\n",
      "1:16:31 PM\n",
      "kindly give me a minute to review the ticket\n",
      "Eddens,Devlin (COACH)\n",
      "1:16:40 PM\n",
      "Metered error in Outlook?\n",
      "Eddens,Devlin (COACH)\n",
      "1:19:15 PM\n",
      "see screen shot. it blips on and off where you cant read it (its the yellow error) and i was able to snap a shot right when it appeared before disappearing again over and over\n",
      "MICHAEL BORCHARDT\n",
      "1:20:05 PM\n",
      "can you add me into bomgar?\n",
      "Eddens,Devlin (COACH)\n",
      "1:20:36 PM\n",
      "yes\n",
      "MICHAEL BORCHARDT\n",
      "1:20:41 PM\n",
      "ty\n",
      "Eddens,Devlin (COACH)\n",
      "1:20:49 PM\n",
      "she should be good to go now, we turned off the metered connection setting and I sent her a successful test email\n",
      "Eddens,Devlin (COACH)\n",
      "1:25:46 PM\n",
      "thanks a lot Devlin. you are awesome\n",
      "MICHAEL BORCHARDT\n",
      "1:26:13 PM\n",
      "what would i use for a KB?\n",
      "MICHAEL BORCHARDT\n",
      "1:26:45 PM\n",
      "My pleasure you are very welcome!! KBB0045163 and Microsoft Outlook - Unable to Connect or Connection is UnavailableKB0104935\n",
      "Eddens,Devlin (COACH)\n",
      "1:26:50 PM\n",
      "thanks\n",
      "MICHAEL BORCHARDT\n",
      "1:27:00 PM\n",
      "\n",
      "\n",
      "I have a question for you. I have been trying to connect to the Microsoft Exchange server for some time now. It seems to be working fine. Is there a way to fix it? I am using a Windows 7 64-bit machine and it seems that the connection is not working. Can you help me? Thanks\n",
      "\n",
      "Michael B. (E-mail: Michael.B.@microsoft.com) (I'm using Windows 8.1 64bit)\n",
      "\n",
      "...\n",
      "The problem is that I can't get the Exchange connection to work properly. The problem with this is I don't know how to get it working properly on my machine. So I tried to use a tool called \"Microsoft Exchange Server\" which is a free\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def generate_summary(text):\n",
    "    # Tokenize input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "    # Generate summary\n",
    "    # Increased max_length and added max_new_tokens\n",
    "    summary_ids = model.generate(input_ids,\n",
    "                                 max_length=500, # Increased to accommodate input and output\n",
    "                                 max_new_tokens=150, # Limit new tokens generated\n",
    "                                 num_beams=2,\n",
    "                                 no_repeat_ngram_size=2,\n",
    "                                 early_stopping=True)\n",
    "\n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "text = '''\n",
    "We will be with you soon.\n",
    "System\n",
    "1:14:11 PM\n",
    "You are currently 1 in queue.\n",
    "System\n",
    "1:14:41 PM\n",
    "INC34955425\n",
    "MICHAEL BORCHARDT\n",
    "1:14:43 PM\n",
    "You are currently 1 in queue.\n",
    "System\n",
    "1:15:41 PM\n",
    "INC34955425\n",
    "MICHAEL BORCHARDT\n",
    "1:16:07 PM\n",
    "Good morning\n",
    "Eddens,Devlin (COACH)\n",
    "1:16:31 PM\n",
    "kindly give me a minute to review the ticket\n",
    "Eddens,Devlin (COACH)\n",
    "1:16:40 PM\n",
    "Metered error in Outlook?\n",
    "Eddens,Devlin (COACH)\n",
    "1:19:15 PM\n",
    "see screen shot. it blips on and off where you cant read it (its the yellow error) and i was able to snap a shot right when it appeared before disappearing again over and over\n",
    "MICHAEL BORCHARDT\n",
    "1:20:05 PM\n",
    "can you add me into bomgar?\n",
    "Eddens,Devlin (COACH)\n",
    "1:20:36 PM\n",
    "yes\n",
    "MICHAEL BORCHARDT\n",
    "1:20:41 PM\n",
    "ty\n",
    "Eddens,Devlin (COACH)\n",
    "1:20:49 PM\n",
    "she should be good to go now, we turned off the metered connection setting and I sent her a successful test email\n",
    "Eddens,Devlin (COACH)\n",
    "1:25:46 PM\n",
    "thanks a lot Devlin. you are awesome\n",
    "MICHAEL BORCHARDT\n",
    "1:26:13 PM\n",
    "what would i use for a KB?\n",
    "MICHAEL BORCHARDT\n",
    "1:26:45 PM\n",
    "My pleasure you are very welcome!! KBB0045163 and Microsoft Outlook - Unable to Connect or Connection is UnavailableKB0104935\n",
    "Eddens,Devlin (COACH)\n",
    "1:26:50 PM\n",
    "thanks\n",
    "MICHAEL BORCHARDT\n",
    "1:27:00 PM\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "summary = generate_summary(text)\n",
    "print(\"summary\" , summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "662618c0-1ed4-4f02-806c-317e4a521329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1ca7f-6d01-4d21-8d4f-645ffde242ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
